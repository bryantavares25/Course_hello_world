# -*- coding: utf-8 -*-
"""Imersão Alura.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1skjMlrktcT2wCtlf5NnqTtWxBKYl0Gnl
"""

import pandas as pd

url_dados = 'https://github.com/alura-cursos/imersaodados3/blob/main/dados/dados_experimentos.zip?raw=true'

dados = pd.read_csv(url_dados, compression = 'zip')

dados['droga'].unique()

dados['tratamento'].value_counts()

dados['tratamento'].value_counts(normalize = True)

dados['tratamento'].value_counts().plot.pie()

dados['tempo'].value_counts().plot.bar()

dados_filtrados = dados[dados['g-0'] > 0]

dados.tail()

dados.shape[0]

rename = dados.columns = dados.columns.str.replace("-", "")

dados.head()

len(dados['droga'].unique())

mapa = {'droga':'composto'}
dados.rename(columns = mapa, inplace = True)

compostos_top5 = dados['composto'].value_counts()[0:5]
compostos_top5_index = compostos_top5.sort_values().index

import seaborn as sns
import matplotlib.pyplot as plt

sns.set()
plt.figure(figsize = (7, 5))
ax = sns.countplot(x = 'composto', data = dados.query('composto in @compostos_top5_index'), order = compostos_top5_index, palette = 'flare')
ax.set_title('Análise quantitativa de experimentos de 5 compostos', fontsize = 20)
ax.set_xlabel('Compostos', fontsize = 12)
ax.set_ylabel('Quantidade de experimentos', fontsize = 12)

plt.show()

dados.describe()

dados.loc[:,'g0':'g771'].describe().T['mean'].hist(bins = 50)

sns.boxplot(x = 'tratamento', y = 'g0' , data = dados)

pd.crosstab(dados['dose'], dados['tempo'])

pd.crosstab([dados['dose'], dados['tempo']], dados['tratamento'], normalize = 'index')

pd.crosstab([dados['dose'], dados['tempo']], dados['tratamento'], values = dados['g0'], aggfunc = 'mean')

sns.scatterplot(x = 'g0', y = 'g8', data = dados)

sns.lmplot(x = 'g0', y = 'g8', data = dados, line_kws = {'color' : 'black'}, col = 'tratamento', row = 'tempo')

dados.loc[:, 'g0': 'g771'].corr()

# Compute the correlation matrix
corr = dados.loc[:, 'c0': 'c10'].corr()

import numpy as np

# Generate a mask for the upper triangle
mask = np.triu(np.ones_like(corr, dtype=bool))

# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(230, 20, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})

resultados = pd.read_csv('https://github.com/alura-cursos/imersaodados3/blob/main/dados/dados_resultados.csv?raw=true')
resultados.head()

contagem_moa = resultados.select_dtypes('int64').sum().sort_values(ascending=False)

resultados['moa'] = resultados.drop('id', axis=1).sum(axis=1)

resultados['a_moa'] = (resultados['moa'] != 0)

dados_combinados = pd.merge(dados, resultados[['id', 'moa', 'a_moa']], on = 'id')

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

x = dados_combinados.select_dtypes('float64')
y = dados_combinados['a_moa']

x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.25, stratify = y, random_state = 5224)

modelo_rlogistica = LogisticRegression(max_iter = 1000)
modelo_rlogistica.fit(x_treino, y_treino)
modelo_rlogistica.score(x_teste, y_teste)

from sklearn.dummy import DummyClassifier
from sklearn.metrics import accuracy_score

modelo_dummy = DummyClassifier('most_frequent')
modelo_dummy.fit(x_treino, y_treino)
previsao = modelo_dummy.predict(x_teste)
accuracy_score(y_teste, previsao)

from sklearn.tree import DecisionTreeClassifier

x = dados_combinados.select_dtypes('float64')
y = dados_combinados['a_moa']

x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.25, stratify = y, random_state = 5224)

treino = []
teste = []

for i in range(1, 15):
  modelo_arvore = DecisionTreeClassifier(max_depth = 10)
  modelo_arvore.fit(x_treino, y_treino)
  treino.append(modelo_arvore.score(x_treino,y_treino))
  teste.append(modelo_arvore.score(x_teste,y_teste))

